{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "sys.path.insert(0, '/'.join(sys.path[0].split('/')[:-1] + ['scripts']))\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from fastprogress.fastprogress import format_time\n",
    "from early_stopping import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsLogging(Callback):\n",
    "    '''Modified stats logging callback to log time stamps'''\n",
    "    def __init__(self, metrics=[compute_accuracy]):\n",
    "        self.train_stats = AvgStats(metrics, True)\n",
    "        self.valid_stats = AvgStats(metrics, False)\n",
    "    \n",
    "    def before_fit(self):\n",
    "        metric_names = ['loss'] + [m.__name__ for m in self.train_stats.metrics]\n",
    "        names = ['epoch'] + [f'train_{n}' for n in metric_names] + [\n",
    "            f'valid_{n}' for n in metric_names] + ['time']\n",
    "        self.logger(names)\n",
    "        \n",
    "    def before_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.model.training else self.valid_stats\n",
    "        stats.accumulate(self.learner)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        stats = [str(self.epoch)]\n",
    "        for o in [self.train_stats, self.valid_stats]:\n",
    "            stats += [f'{v:.6f}' for v in o.avg_stats]\n",
    "        stats += [format_time(time.time() - self.start_time)]\n",
    "        self.logger(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class ProgressViewer(Callback):\n",
    "    '''Callback utilizing FastAI frontend lib to display neat looking training progress''' \n",
    "    def before_fit(self):\n",
    "        self.mbar = master_bar(range(self.num_epochs))\n",
    "        self.mbar.on_iter_begin()\n",
    "        self.learner.logger = partial(self.mbar.write, table=True)\n",
    "        \n",
    "    def after_fit(self): \n",
    "        self.mbar.on_iter_end()\n",
    "        \n",
    "    def after_batch(self):\n",
    "        self.pb.update(self.iters_count)\n",
    "    \n",
    "    def set_pb(self, data_loader):\n",
    "        self.pb = progress_bar(data_loader, parent=self.mbar)\n",
    "        self.mbar.update(self.epoch)\n",
    "        \n",
    "    def before_epoch(self): \n",
    "        self.set_pb(self.data_bunch.train_dl)\n",
    "        \n",
    "    def before_valid(self): \n",
    "        self.set_pb(self.data_bunch.valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch = get_data_bunch(*get_mnist_data(), batch_size=64)\n",
    "model = get_lin_model(data_bunch)\n",
    "optimizer = DynamicOpt(list(model.parameters()), learning_rate=0.1)\n",
    "loss_fn = CrossEntropy()\n",
    "callbacks = [ProgressViewer(), StatsLogging()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DataBunch) \n",
      "    (DataLoader) \n",
      "        (Dataset) x: (50000, 784), y: (50000,)\n",
      "        (Sampler) total: 50000, batch_size: 64, shuffle: True\n",
      "    (DataLoader) \n",
      "        (Dataset) x: (10000, 784), y: (10000,)\n",
      "        (Sampler) total: 10000, batch_size: 128, shuffle: False\n",
      "(Model)\n",
      "    Linear(784, 50)\n",
      "    ReLU()\n",
      "    Linear(50, 10)\n",
      "(CrossEntropy)\n",
      "(DynamicOpt) hyper_params: ['learning_rate']\n",
      "(Callbacks) ['TrainEval', 'ProgressViewer', 'StatsLogging']\n"
     ]
    }
   ],
   "source": [
    "learner = Learner(data_bunch, model, loss_fn, optimizer, callbacks)\n",
    "print(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
