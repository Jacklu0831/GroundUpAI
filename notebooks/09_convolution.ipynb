{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "sys.path.insert(0, '/'.join(sys.path[0].split('/')[:-1] + ['scripts']))\n",
    "\n",
    "from functools import reduce\n",
    "import torch.nn as nn # imported for testing my convolution layer\n",
    "from torch.nn.functional import pad as torch_pad\n",
    "from linear import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pad_tensor(inp, pad, value=0):\n",
    "    '''Util function for padding inp tensor'''\n",
    "    return torch_pad(inp, [pad]*4, 'constant', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_mnist_data()\n",
    "x_train = x_train[:100].view(-1, 1, 28, 28)\n",
    "torch_conv = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.500054657459259, std: 0.8764498829841614\n"
     ]
    }
   ],
   "source": [
    "torch_conv_out_mean = 0.\n",
    "torch_conv_out_std = 0.\n",
    "for _ in range(100):\n",
    "    torch_conv.weight = nn.Parameter(init_4d_weight((4, 1, 3, 3), 0.))\n",
    "    torch_conv_out = torch_conv(x_train).clamp_min(0.)\n",
    "    torch_conv_out_mean += torch_conv_out.mean()\n",
    "    torch_conv_out_std += torch_conv_out.std()\n",
    "torch_conv_out_mean /= 100.0\n",
    "torch_conv_out_std /= 100.0\n",
    "print(f'mean: {torch_conv_out_mean}, std: {torch_conv_out_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Reshape(Module):\n",
    "    '''Reshape layer'''\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "    \n",
    "    def fwd(self, inp): \n",
    "        return inp.view(-1, *self.shape)\n",
    "    \n",
    "    def bwd(self, out, inp): \n",
    "        # simply reverse the fwd\n",
    "        inp.g = out.g.reshape(-1, reduce(lambda x,y: x*y, self.shape))\n",
    "    \n",
    "    def __repr__(self, t=''): \n",
    "        return f\"{t+'    '}Reshape{self.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Flatten(Module):\n",
    "    '''Flatten layer'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def fwd(self, inp):\n",
    "        self.batch_size, *self.shape = inp.shape\n",
    "        return inp.view(self.batch_size, -1)\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g.view(-1, *self.shape)\n",
    "        \n",
    "    def __repr__(self, t=''):\n",
    "        return f\"{t+'    '}Flatten()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Conv(Module):\n",
    "    '''Convolutional layer'''\n",
    "    def __init__(self, c_in, c_out, k_s=3, stride=1, pad=0, leak=1.):\n",
    "        super().__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.k_s = k_s\n",
    "        self.stride = stride\n",
    "        self.pad = pad   \n",
    "        \n",
    "        self.w = Parameter(init_4d_weight((c_out, c_in, k_s, k_s), leak))\n",
    "        self.b = Parameter(torch.zeros(c_out))\n",
    "    \n",
    "    def fwd(self, inp):\n",
    "        batch_size, _, in_h, in_w = inp.shape\n",
    "        inp = pad_tensor(inp, self.pad)\n",
    "        _, _, p_h, p_w = inp.shape\n",
    "\n",
    "        # init output\n",
    "        out_dim = lambda d: (d + 2 * self.pad - self.k_s) // self.stride + 1\n",
    "        out = torch.zeros(batch_size, self.c_out, out_dim(in_h), out_dim(in_w))\n",
    "\n",
    "        # compute output cell by cell\n",
    "        for i in range(0, p_h - self.k_s + 1, self.stride):\n",
    "            for j in range(0, p_w - self.k_s + 1, self.stride):\n",
    "                receptive_field = inp[:, :, i:i+self.k_s, j:j+self.k_s].unsqueeze(1)\n",
    "                out[:, :, i//self.stride, j//self.stride] = (receptive_field * self.w.data).sum((-1,-2,-3)) + self.b.data\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        # source of var names and math calcs: https://medium.com/@pavisj/convolutions-and-backpropagations-46026a8f5d2c\n",
    "        dL = out.g\n",
    "        X, F, B = pad_tensor(inp, self.pad), self.w.data, self.b.data\n",
    "        dX, dF, dB = torch.zeros_like(X), torch.zeros_like(F), torch.zeros_like(B)\n",
    "        k_s = F.shape[2]\n",
    "        _, _, out_h, out_w = dL.shape\n",
    "\n",
    "        # each cell in output are computed from a receptive field in input\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                i_s, j_s = i * self.stride, j * self.stride\n",
    "                receptive_field = X[:, :, j_s: j_s+k_s, i_s: i_s+k_s].unsqueeze(1)\n",
    "                dL_section = dL[:, :, j, i][..., None, None, None]\n",
    "\n",
    "                dX[:, :, j_s: j_s+k_s, i_s: i_s+k_s] += (F * dL_section).sum(1)\n",
    "                dF += (receptive_field * dL_section).sum(0)\n",
    "                dB += dL[:, :, j, i].sum(0)\n",
    "\n",
    "        self.w.update(dF)\n",
    "        self.b.update(dB)\n",
    "        inp.g = dX if self.pad == 0 else dX[:, :, self.pad: -self.pad, self.pad: -self.pad]\n",
    "    \n",
    "    def __repr__(self, t=''): \n",
    "        return f\"{t+'    '}Conv({self.c_in}, {self.c_out}, {self.k_s}, {self.stride})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_conv_model(data_bunch):\n",
    "    '''Util function to get convolutional model based on data bunch shape'''\n",
    "    in_dim = data_bunch.train_ds.x_data.shape[1]\n",
    "    out_dim = int(max(data_bunch.train_ds.y_data) + 1)\n",
    "    assert in_dim == 1 * 28 * 28\n",
    "    return Sequential(Reshape((1, 28, 28)),\n",
    "                      Conv(1, 8, 5, stride=4, pad=2, leak=0.), # 8, 7, 7 \n",
    "                      ReLU(), \n",
    "                      Conv(8, 16, 3, stride=2, pad=1, leak=1.), # 16, 4, 4\n",
    "                      Flatten(),\n",
    "                      Linear(256, out_dim, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (12, 18, 37, 37)\n",
      "padding: 3\n",
      "stride: 3\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(12, 18, 37, 37)\n",
    "batch_size = inp.shape[0]\n",
    "c_in, c_out = inp.shape[1], 7\n",
    "k_s = 5\n",
    "pad = 3\n",
    "stride = 3\n",
    "\n",
    "print(f'input shape: {tuple(inp.shape)}')\n",
    "print(f'padding: {pad}')\n",
    "print(f'stride: {stride}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight shape (7, 18, 5, 5)\n",
      "bias shape: (7,)\n",
      "output shape: (12, 7, 13, 13)\n"
     ]
    }
   ],
   "source": [
    "torch_conv = nn.Conv2d(c_in, c_out, k_s, stride, pad)\n",
    "torch_res = torch_conv(inp)\n",
    "\n",
    "conv_layer = Conv(c_in, c_out, k_s, stride, pad)\n",
    "conv_layer.w = Parameter(torch_conv.weight)\n",
    "conv_layer.b = Parameter(torch_conv.bias)\n",
    "my_res = conv_layer.fwd(inp)\n",
    "\n",
    "print(f'weight shape {tuple(conv_layer.w.data.shape)}')\n",
    "print(f'bias shape: {tuple(conv_layer.b.data.shape)}')\n",
    "print(f'output shape: {tuple(my_res.shape)}')\n",
    "\n",
    "assert(my_res.shape == torch_res.shape)\n",
    "test_near(my_res, torch_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_mnist_data()\n",
    "x_train, y_train, x_valid, y_valid = x_train[:8], y_train[:8], x_valid[:2], y_valid[:2]\n",
    "\n",
    "data_bunch = get_data_bunch(x_train, y_train, x_valid, y_valid, batch_size=64)\n",
    "model = get_conv_model(data_bunch)\n",
    "loss_fn = CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    Reshape(1, 28, 28)\n",
       "    Conv(1, 8, 5, 4)\n",
       "    ReLU()\n",
       "    Conv(8, 16, 3, 2)\n",
       "    Flatten()\n",
       "    Linear(256, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(x_train), y_train)\n",
    "loss_fn.backward()\n",
    "model.backward()\n",
    "\n",
    "xtg = x_train.g.clone()\n",
    "w1g = model.layers[1].w.grad.clone()\n",
    "b1g = model.layers[1].b.grad.clone()\n",
    "w2g = model.layers[3].w.grad.clone()\n",
    "b2g = model.layers[3].b.grad.clone()\n",
    "w3g = model.layers[5].w.grad.clone()\n",
    "b3g = model.layers[5].b.grad.clone()\n",
    "\n",
    "x_train2 = x_train.clone().requires_grad_(True)\n",
    "model.layers[1].w.data.requires_grad_(True)\n",
    "model.layers[1].b.data.requires_grad_(True)\n",
    "model.layers[3].w.data.requires_grad_(True)\n",
    "model.layers[3].b.data.requires_grad_(True)\n",
    "model.layers[5].w.data.requires_grad_(True)\n",
    "model.layers[5].b.data.requires_grad_(True)\n",
    "\n",
    "loss = loss_fn(model(x_train2), y_train)\n",
    "loss.backward()\n",
    "\n",
    "test_near(w1g, model.layers[1].w.data.grad)\n",
    "test_near(b1g, model.layers[1].b.data.grad)\n",
    "test_near(w2g, model.layers[3].w.data.grad)\n",
    "test_near(b2g, model.layers[3].b.data.grad)\n",
    "test_near(w3g, model.layers[5].w.data.grad)\n",
    "test_near(b3g, model.layers[5].b.data.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
