{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet\n",
    "paper: https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "sys.path.insert(0, '/'.join(sys.path[0].split('/')[:-1] + ['scripts']))\n",
    "\n",
    "from stateful_optim import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual block equation:\n",
    "\n",
    "y = F(x, {Wi}) + x\n",
    "\n",
    "\\\n",
    "Each res block has two \"subModels\", a F(x, {Wi}) and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_basic_block(i, o, s):\n",
    "    '''Get basic ResNet block.\n",
    "        i: channel in\n",
    "        o: channel out\n",
    "        s: stride size\n",
    "    '''\n",
    "    return Sequential(Conv(i, o, 3, s),\n",
    "                      BatchNorm(o),\n",
    "                      ReLU(),\n",
    "                      Conv(o, o*4, 3, 1),\n",
    "                      BatchNorm(o))\n",
    "\n",
    "def get_bottleneck(i, o):\n",
    "    '''Get bottleneck ResNet block.\n",
    "        i: channel in\n",
    "        o: channel out\n",
    "    '''\n",
    "    return Sequential(Conv(i, o, 1, 1),\n",
    "                      BatchNorm(o),\n",
    "                      ReLU(),\n",
    "                      Conv(o, o, 3, 1),\n",
    "                      BatchNorm(o),\n",
    "                      ReLU(),\n",
    "                      Conv(o, o*4, 1, 1),\n",
    "                      BatchNorm(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    Conv(32, 64, 3, 1)\n",
       "    BatchNorm()\n",
       "    ReLU()\n",
       "    Conv(64, 256, 3, 1)\n",
       "    BatchNorm()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_basic_block(32, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    Conv(32, 64, 1, 1)\n",
       "    BatchNorm()\n",
       "    ReLU()\n",
       "    Conv(64, 64, 3, 1)\n",
       "    BatchNorm()\n",
       "    ReLU()\n",
       "    Conv(64, 256, 1, 1)\n",
       "    BatchNorm()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bottleneck(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResLayer(Module):\n",
    "    def __init__(self, i, o, s, bottleneck):\n",
    "        '''Get ResLayer (almost a ResBlock but not including the final activation).\n",
    "            i: channel in\n",
    "            o: channel out\n",
    "            s: stride size\n",
    "            bottleneck: boolean of whether the resblock is basic or bottleneck\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.i, self.o, self.s, self.bottleneck = i, o, s, bottleneck\n",
    "        self.x_layer = Identity()\n",
    "        self.Fx_layer = get_bottleneck(i, o) if bottleneck else get_basic_block(self.i, self.o, self.s)\n",
    "        \n",
    "    def fwd(self, inp):\n",
    "        self.fx = self.Fx_layer(inp)\n",
    "        self.x = self.x_layer(inp)\n",
    "        self.out = self.fx + self.x\n",
    "        return self.out\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        self.fx.g = out.g\n",
    "        self.x.g = out.g\n",
    "        self.Fx_layer.backward()\n",
    "        self.x_layer.backward()\n",
    "    \n",
    "    def parameters(self):\n",
    "        for sub_model in [self.Fx_layer, self.x_layer]:\n",
    "            for param in sub_model.parameters():\n",
    "                yield param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock(SubModel):\n",
    "    def __init__(self, i, o, s, bottleneck):\n",
    "        '''ResBlock (ResLayer + Activation).\n",
    "            i: channel in\n",
    "            o: channel out\n",
    "            s: stride size\n",
    "            bottleneck: boolean of whether the resblock is basic or bottleneck\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.i, self.o, self.s, self.bottleneck = i, o, s, bottleneck\n",
    "        self.sub_model = Sequential(ResLayer(i, o, s, bottleneck),\n",
    "                                    ReLU())\n",
    "    \n",
    "    def __repr__(self, t=''):\n",
    "        return f\"{t+'    '}{'Bottleneck' if self.bottleneck else 'BasicBlock'}({self.i}, {self.o}, {self.s})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Bottleneck(32, 64, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResBlock(32, 64, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    BasicBlock(32, 64, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResBlock(32, 64, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlockGroup(SubModel):\n",
    "    def __init__(self, i, o, num_blocks, bottleneck):\n",
    "        '''Group of ResBlocks.\n",
    "            i: channel in\n",
    "            o: channel out\n",
    "            num_blocks: number of resblockss\n",
    "            bottleneck: boolean of whether the resblocks are basic or bottleneck\n",
    "        '''\n",
    "        layers = [ResBlock(i, o, 2, bottleneck)]\n",
    "        for _ in range(num_blocks-1):\n",
    "            layers.append(ResBlock(o, o, 1, bottleneck))\n",
    "        self.sub_model = Sequential(*layers)\n",
    "        \n",
    "    def __repr__(self, t=''):\n",
    "        return f\"{self.sub_model.__repr__(t+'    ')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_res_head(in_shape, o):\n",
    "    '''ResNet head (before ResBlocks).\n",
    "        in_shape: input shape before conv bn relu and pool\n",
    "        o: channel out\n",
    "    '''\n",
    "    return [Reshape(in_shape),\n",
    "            Conv(in_shape[0], o, 7, 2),\n",
    "            BatchNorm(o),\n",
    "            ReLU(),\n",
    "            MaxPool(3, 2, 1)]\n",
    "\n",
    "def get_res_tail(h, o):\n",
    "    '''ResNet tail (after ResBlocks).\n",
    "        h: number of hidden cells\n",
    "        o: channel out\n",
    "    '''\n",
    "    return [AvgPool(1, 1, 0),\n",
    "            Flatten(),\n",
    "            Linear(h, o, True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    Reshape(1, 28, 28)\n",
       "    Conv(1, 64, 7, 2)\n",
       "    BatchNorm()\n",
       "    ReLU()\n",
       "    MaxPool(3, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sequential(get_res_head((1, 28, 28), 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    AvgPool(1, 1)\n",
       "    Flatten()\n",
       "    Linear(1024, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sequential(get_res_tail(1024, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "name2depths = {18:  [2, 2, 2,  2],\n",
    "               34:  [3, 4, 6,  3],\n",
    "               50:  [3, 4, 6,  3],\n",
    "               101: [3, 4, 23, 3],\n",
    "               152: [3, 8, 36, 3]}\n",
    "\n",
    "class ResNet(SubModel):\n",
    "    def __init__(self, n_layer, in_shape=(3,28,28), out=100):\n",
    "        '''ResNet model that is able to create ResNets with different number of layers adaptively.\n",
    "            n_layer: number of resnet layers (18, 34...)\n",
    "            in_shape: input image shape\n",
    "            out: output number of labels\n",
    "        '''\n",
    "        self.name = f'ResNet {n_layer}'\n",
    "        bottleneck = n_layer > 34\n",
    "        channels = [64, 128, 256, 512]\n",
    "        depths = name2depths[n_layer]\n",
    "        \n",
    "        head = get_res_head(in_shape, channels[0])\n",
    "        body = [ResBlockGroup(channels[0], channels[0], depths[0], bottleneck)]\n",
    "        for i, o, depth in zip(channels, channels[1:], depths[1:]):\n",
    "            body.append(ResBlockGroup(i, o, depth, bottleneck))\n",
    "        tail = get_res_tail(channels[-1]*(4 if bottleneck else 1), out)\n",
    "        self.sub_model = Sequential(head + body + tail)\n",
    "    \n",
    "    def __repr__(self, t=''):\n",
    "        return f'{t}{self.sub_model}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    Reshape(1, 48, 48)\n",
       "    Conv(1, 64, 7, 2)\n",
       "    BatchNorm()\n",
       "    ReLU()\n",
       "    MaxPool(3, 2)\n",
       "        BasicBlock(64, 64, 2)\n",
       "        BasicBlock(64, 64, 1)\n",
       "        BasicBlock(64, 128, 2)\n",
       "        BasicBlock(128, 128, 1)\n",
       "        BasicBlock(128, 256, 2)\n",
       "        BasicBlock(256, 256, 1)\n",
       "        BasicBlock(256, 512, 2)\n",
       "        BasicBlock(512, 512, 1)\n",
       "    AvgPool(1, 1)\n",
       "    Flatten()\n",
       "    Linear(512, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet(18, (1, 48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    Reshape(3, 128, 128)\n",
       "    Conv(3, 64, 7, 2)\n",
       "    BatchNorm()\n",
       "    ReLU()\n",
       "    MaxPool(3, 2)\n",
       "        BasicBlock(64, 64, 2)\n",
       "        BasicBlock(64, 64, 1)\n",
       "        BasicBlock(64, 64, 1)\n",
       "        BasicBlock(64, 128, 2)\n",
       "        BasicBlock(128, 128, 1)\n",
       "        BasicBlock(128, 128, 1)\n",
       "        BasicBlock(128, 128, 1)\n",
       "        BasicBlock(128, 256, 2)\n",
       "        BasicBlock(256, 256, 1)\n",
       "        BasicBlock(256, 256, 1)\n",
       "        BasicBlock(256, 256, 1)\n",
       "        BasicBlock(256, 256, 1)\n",
       "        BasicBlock(256, 256, 1)\n",
       "        BasicBlock(256, 512, 2)\n",
       "        BasicBlock(512, 512, 1)\n",
       "        BasicBlock(512, 512, 1)\n",
       "    AvgPool(1, 1)\n",
       "    Flatten()\n",
       "    Linear(512, 25)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet(34, (3, 128, 128), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    Reshape(3, 28, 28)\n",
       "    Conv(3, 64, 7, 2)\n",
       "    BatchNorm()\n",
       "    ReLU()\n",
       "    MaxPool(3, 2)\n",
       "        Bottleneck(64, 64, 2)\n",
       "        Bottleneck(64, 64, 1)\n",
       "        Bottleneck(64, 64, 1)\n",
       "        Bottleneck(64, 128, 2)\n",
       "        Bottleneck(128, 128, 1)\n",
       "        Bottleneck(128, 128, 1)\n",
       "        Bottleneck(128, 128, 1)\n",
       "        Bottleneck(128, 256, 2)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 512, 2)\n",
       "        Bottleneck(512, 512, 1)\n",
       "        Bottleneck(512, 512, 1)\n",
       "    AvgPool(1, 1)\n",
       "    Flatten()\n",
       "    Linear(2048, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Model)\n",
       "    Reshape(3, 28, 28)\n",
       "    Conv(3, 64, 7, 2)\n",
       "    BatchNorm()\n",
       "    ReLU()\n",
       "    MaxPool(3, 2)\n",
       "        Bottleneck(64, 64, 2)\n",
       "        Bottleneck(64, 64, 1)\n",
       "        Bottleneck(64, 64, 1)\n",
       "        Bottleneck(64, 128, 2)\n",
       "        Bottleneck(128, 128, 1)\n",
       "        Bottleneck(128, 128, 1)\n",
       "        Bottleneck(128, 128, 1)\n",
       "        Bottleneck(128, 256, 2)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 256, 1)\n",
       "        Bottleneck(256, 512, 2)\n",
       "        Bottleneck(512, 512, 1)\n",
       "        Bottleneck(512, 512, 1)\n",
       "    AvgPool(1, 1)\n",
       "    Flatten()\n",
       "    Linear(2048, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DataBunch) \n",
      "    (DataLoader) \n",
      "        (Dataset) x: (50000, 784), y: (50000,)\n",
      "        (Sampler) total: 50000, batch_size: 64, shuffle: True\n",
      "    (DataLoader) \n",
      "        (Dataset) x: (10000, 784), y: (10000,)\n",
      "        (Sampler) total: 10000, batch_size: 128, shuffle: False\n",
      "(Model)\n",
      "(Model)\n",
      "    Reshape(3, 28, 28)\n",
      "    Conv(3, 64, 7, 2)\n",
      "    BatchNorm()\n",
      "    ReLU()\n",
      "    MaxPool(3, 2)\n",
      "        BasicBlock(64, 64, 2)\n",
      "        BasicBlock(64, 64, 1)\n",
      "        BasicBlock(64, 128, 2)\n",
      "        BasicBlock(128, 128, 1)\n",
      "        BasicBlock(128, 256, 2)\n",
      "        BasicBlock(256, 256, 1)\n",
      "        BasicBlock(256, 512, 2)\n",
      "        BasicBlock(512, 512, 1)\n",
      "    AvgPool(1, 1)\n",
      "    Flatten()\n",
      "    Linear(512, 100)\n",
      "(CrossEntropy)\n",
      "(StatefulOpt) steppers: ['adam', 'l2_reg'], stats: ['ExpWeightedGrad', 'ExpWeightedSqrGrad', 'StepCount']\n",
      "(Callbacks) ['TrainEval', 'StatsLogging', 'Recorder']\n"
     ]
    }
   ],
   "source": [
    "hyper_params = {'learning_rate':0.001, 'weight_decay':1e-4}\n",
    "schedule = combine_schedules([0.4, 0.6], one_cycle_cos(0.0001, 0.003, 0.0001))\n",
    "\n",
    "data_bunch = get_data_bunch(*get_mnist_data(), batch_size=64)\n",
    "model = Sequential(ResNet(18))\n",
    "loss_fn = CrossEntropy()\n",
    "optimizer = adam_opt(model, **hyper_params)\n",
    "callbacks = [StatsLogging(), Recorder()]\n",
    "\n",
    "learner = Learner(data_bunch, model, loss_fn, optimizer, callbacks)\n",
    "print(learner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
