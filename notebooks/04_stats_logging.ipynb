{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "from os.path import join\n",
    "\n",
    "sys.path.insert(0, '/'.join(sys.path[0].split('/')[:-1] + ['scripts']))\n",
    "from callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgStats():\n",
    "    def __init__(self, metrics, training): \n",
    "        self.metrics = metrics\n",
    "        self.training = training\n",
    "    \n",
    "    def reset(self):\n",
    "        self.count = 0\n",
    "        self.total_loss = torch.Tensor([0])\n",
    "        self.totals = [torch.Tensor([0])] * len(self.metrics)\n",
    "        \n",
    "    @property\n",
    "    def all_stats(self): return [self.total_loss] + self.totals\n",
    "    \n",
    "    @property\n",
    "    def avg_stats(self): return [s.item()/self.count for s in self.all_stats]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if not self.count: \n",
    "            return ''\n",
    "        return f\"{'train' if self.training else 'valid'} metrics - {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, runner):\n",
    "        batch_size = runner.x_batch.shape[0]\n",
    "        self.count += batch_size\n",
    "        self.total_loss = runner.loss * batch_size\n",
    "        for i, metric in enumerate(self.metrics):\n",
    "            self.totals[i] += metric(runner.pred, runner.y_batch) * batch_size\n",
    "\n",
    "class StatsLogging(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats = AvgStats(metrics, True)\n",
    "        self.valid_stats = AvgStats(metrics, False)\n",
    "        \n",
    "    def before_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.model.training else self.valid_stats\n",
    "        stats.accumulate(self.runner)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(f'Epoch - {self.epoch}\\n{self.train_stats}\\n{self.valid_stats}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 50\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "learning_rate = 0.1\n",
    "\n",
    "data_bunch = get_data_bunch(*get_mnist_data(), batch_size)\n",
    "model, optimizer = get_model(data_bunch, learning_rate, num_hidden)\n",
    "loss_fn = CrossEntropy()\n",
    "learner = Learner(model, optimizer, loss_fn, data_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DataBunch) \n",
      "\t(DataLoader) \n",
      "\t\t(Dataset) x: (50000, 784), y: (50000,)\n",
      "\t\t(Sampler) total: 50000, batch_size: 64, shuffle: True\n",
      "\t(DataLoader) \n",
      "\t\t(Dataset) x: (10000, 784), y: (10000,)\n",
      "\t\t(Sampler) total: 10000, batch_size: 128, shuffle: False\n",
      "(Sequential)\n",
      "\t(Layer1) Linear(784, 50)\n",
      "\t(Layer2) ReLU()\n",
      "\t(Layer3) Linear(50, 10)\n",
      "(CrossEntropy)\n",
      "(Optimizer) num_params: 4, learning_rate: 0.1\n",
      "(Callbacks) TrainEval StatsLogging\n"
     ]
    }
   ],
   "source": [
    "runner = Runner(learner, [StatsLogging([compute_accuracy])])\n",
    "print(runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1\n",
      "train metrics - [0.00021775859832763673, 0.91726]\n",
      "valid metrics - [0.00012849409580230713, 0.9443]\n",
      "\n",
      "Epoch - 2\n",
      "train metrics - [4.575530052185059e-05, 0.9597]\n",
      "valid metrics - [2.5315427780151367e-05, 0.9651]\n",
      "\n",
      "Epoch - 3\n",
      "train metrics - [1.922694206237793e-05, 0.97048]\n",
      "valid metrics - [1.1928081512451172e-05, 0.9666]\n",
      "\n",
      "Epoch - 4\n",
      "train metrics - [3.533562660217285e-05, 0.97454]\n",
      "valid metrics - [9.833717346191407e-06, 0.9662]\n",
      "\n",
      "Epoch - 5\n",
      "train metrics - [7.881155014038086e-06, 0.97778]\n",
      "valid metrics - [1.0901546478271485e-05, 0.969]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
