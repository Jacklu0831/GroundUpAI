{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "from os.path import join\n",
    "import math\n",
    "\n",
    "sys.path.insert(0, '/'.join(sys.path[0].split('/')[:-1] + ['scripts']))\n",
    "from operations import *\n",
    "from fcn_revised import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.dataset), self.batch_size):\n",
    "            yield self.dataset[i: i+self.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x_chunk, y_chunk):\n",
    "        self.x_chunk = x_chunk\n",
    "        self.y_chunk = y_chunk\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_chunk)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x_chunk[i], self.y_chunk[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def softmax(inp):\n",
    "    # prone to overflow (floating aint precise)\n",
    "    return inp.exp() / inp.exp().sum(-1, keepdim=True)\n",
    "\n",
    "def log_sum_exp(inp):\n",
    "    e = inp.max(-1)[0]\n",
    "    return e + (inp - e[:, None]).exp().sum(-1).log()\n",
    "    \n",
    "def log_softmax(inp):\n",
    "    # LogSumExp trick to avoid floating point error\n",
    "    return inp - log_sum_exp(inp).unsqueeze(-1)\n",
    "\n",
    "def nll_loss(pre, tar):\n",
    "    # use multiple indexing \n",
    "    return -pre[range(tar.shape[0]), tar].mean()\n",
    "\n",
    "def cross_entropy(inp, tar):\n",
    "    return nll_loss(log_softmax(inp), tar)\n",
    "\n",
    "def accuracy(pre, tar):\n",
    "    return (torch.argmax(pre, dim=1) == tar).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "model = Model(m, nh, c)\n",
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = nll_loss(log_softmax(pred), y_train)\n",
    "loss2 = cross_entropy(pred, y_train)\n",
    "loss3 = F.nll_loss(F.log_softmax(pred, -1), y_train)\n",
    "loss4 = F.cross_entropy(pred, y_train)\n",
    "\n",
    "test_near(loss1, loss2)\n",
    "test_near(loss2, loss3)\n",
    "test_near(loss3, loss4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, parameters, learning_rate):\n",
    "        self.parameters = list(parameters)\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def step(self):\n",
    "        for param in self.parameters:\n",
    "            param.step(self.learning_rate)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for param in self.parameters:\n",
    "            param.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(num_epochs, model, optim, loss_func, ds_train, ds_valid):\n",
    "#     for epoch in range(num_epochs):\n",
    "#         for batch in range(math.ceil(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Linear(in_dim, nh), ReLU(), Linear(nh, out_dim, True))\n",
    "optimizer = Optimizer(model.parameters(), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_mnist_data()\n",
    "x_train, x_valid = normalize_data(x_train, x_valid)\n",
    "\n",
    "batch_size = 64\n",
    "num_hidden = 50 # hidden cells\n",
    "learning_rate = 0.5\n",
    "(n, m), c = x_train.shape, int(y_train.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
