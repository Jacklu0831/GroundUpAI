{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "from os.path import join\n",
    "\n",
    "sys.path.insert(0, '/'.join(sys.path[0].split('/')[:-1] + ['scripts']))\n",
    "from convolution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MaxPool2d(Module):\n",
    "    def __init__(self, k_s=3, stride=1, pad=0):\n",
    "        super().__init__()\n",
    "        self.k_s = k_s\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def fwd(self, inp):\n",
    "        batch_size, in_c, in_h, in_w = inp.shape\n",
    "        out_dim = lambda d: (d + 2 * self.pad - self.k_s) // self.stride + 1\n",
    "        out_c, out_h, out_w = in_c, out_dim(in_h), out_dim(in_w)\n",
    "\n",
    "        padded = pad_tensor(inp, self.pad, inp.min()) if self.pad > 0 else inp\n",
    "        out = torch.zeros(batch_size, out_c, out_h, out_w)\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                i_s, j_s = i * self.stride, j * self.stride\n",
    "                in_window = padded[:, :, i_s: i_s+self.k_s, j_s: j_s+self.k_s]\n",
    "                out[:,:,i,j] = in_window.max(-1)[0].max(-1)[0]\n",
    "        return out\n",
    "            \n",
    "    def bwd(self, out, inp):\n",
    "        dL = out.g\n",
    "        batch_size, out_c, out_h, out_w = dL.shape\n",
    "        \n",
    "        padded = pad_tensor(inp, self.pad, inp.min()) if self.pad > 0 else inp\n",
    "        dX = torch.zeros_like(padded)\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                i_s, j_s = i*stride, j*stride\n",
    "                inp_w = padded[:, :, i_s:i_s+k_s, j_s:j_s+k_s]                \n",
    "                mask = torch.zeros_like(inp_w)\n",
    "                for i in range(mask.shape[0]):\n",
    "                    for j in range(mask.shape[1]):\n",
    "                        mask[i,j,:,:] = inp_w[i,j,:,:] == inp_w[i,j,:,:].max()\n",
    "                dX[:, :, i_s:i_s+k_s, j_s:j_s+k_s] += dL[:,:,i,j][...,None,None] * mask\n",
    "        padded.g = dX\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MaxPool2d(kernel_size: {self.k_s}, stride: {self.stride}, pad: {self.pad})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgPool2d(Module):\n",
    "    def __init__(self, k_s=3, stride=1, pad=0):\n",
    "        super().__init__()\n",
    "        self.k_s = k_s\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def fwd(self, inp):\n",
    "        batch_size, in_c, in_h, in_w = inp.shape\n",
    "        out_dim = lambda d: (d + 2 * self.pad - self.k_s) // self.stride + 1\n",
    "        out_c, out_h, out_w = in_c, out_dim(in_h), out_dim(in_w)\n",
    "\n",
    "        padded = pad_tensor(inp, self.pad) if self.pad > 0 else inp\n",
    "        out = torch.zeros(batch_size, out_c, out_h, out_w)\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                i_s, j_s = i * self.stride, j * self.stride\n",
    "                in_window = padded[:, :, i_s: i_s+self.k_s, j_s: j_s+self.k_s]\n",
    "                out[:,:,i,j] = torch.mean(in_window, (-1, -2))\n",
    "        return out\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        dL = out.g\n",
    "        batch_size, out_c, out_h, out_w = dL.shape\n",
    "        \n",
    "        padded = pad_tensor(inp, self.pad) if self.pad > 0 else inp\n",
    "        dX = torch.zeros_like(padded)\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                i_s, j_s = i*self.stride, j*self.stride\n",
    "                dX[:, :, i_s:i_s+self.k_s, j_s:j_s+self.k_s] += dL[:,:,i,j][...,None,None] / (self.k_s ** 2)\n",
    "        padded.g = dX\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f'AvgPool2d(kernel: {self.k_s}, stride: {self.stride}, pad: {self.pad})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, _, _, _ = get_mnist_data()\n",
    "x_train = x_train[:100].view(-1, 1, 28, 28)\n",
    "k_s = 5\n",
    "stride = 2\n",
    "pad = 0\n",
    "torch_max = nn.MaxPool2d(k_s, stride, pad)(x_train)\n",
    "torch_avg = nn.AvgPool2d(k_s, stride, pad)(x_train)\n",
    "my_max = MaxPool2d(k_s, stride, pad).fwd(x_train)\n",
    "my_avg = AvgPool2d(k_s, stride, pad).fwd(x_train)\n",
    "\n",
    "assert(torch_max.shape == my_max.shape)\n",
    "assert(torch_avg.shape == my_avg.shape)\n",
    "test_near(torch_max, my_max)\n",
    "test_near(torch_avg, my_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_pool_model(data_bunch):\n",
    "    return Sequential(Reshape((1, 28, 28)),\n",
    "                      Conv2d(c_in=1, c_out=4, k_s=5, stride=2, pad=1), # 4, 13, 13\n",
    "                      AvgPool2d(k_s=2, pad=0), # 4, 12, 12\n",
    "                      Conv2d(c_in=4, c_out=16, stride=2, leak=1.), # 16, 5, 5\n",
    "                      Flatten(),\n",
    "                      Linear(400, 64),\n",
    "                      ReLU(),\n",
    "                      Linear(64, 10, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_mnist_data()\n",
    "x_train, y_train, x_valid, y_valid = x_train[:8], y_train[:8], x_valid[:2], y_valid[:2]\n",
    "\n",
    "data_bunch = get_data_bunch(x_train, y_train, x_valid, y_valid, batch_size=64)\n",
    "model = get_conv_pool_model(data_bunch)\n",
    "loss_fn = CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential)\n",
       "\t(Layer1) Reshape(1, 28, 28)\n",
       "\t(Layer2) Conv2D(in: 1, out: 4, kernel: 5, stride: 2, pad: 1)\n",
       "\t(Layer3) AvgPool2d(kernel: 2, stride: 1, pad: 0)\n",
       "\t(Layer4) Conv2D(in: 4, out: 16, kernel: 3, stride: 2, pad: 0)\n",
       "\t(Layer5) Flatten()\n",
       "\t(Layer6) Linear(400, 64)\n",
       "\t(Layer7) ReLU()\n",
       "\t(Layer8) Linear(64, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(x_train), y_train)\n",
    "loss_fn.backward()\n",
    "model.backward()\n",
    "\n",
    "xtg = x_train.g.clone()\n",
    "w1g = model.layers[1].w.grad.clone()\n",
    "b1g = model.layers[1].b.grad.clone()\n",
    "w2g = model.layers[3].w.grad.clone()\n",
    "b2g = model.layers[3].b.grad.clone()\n",
    "w3g = model.layers[5].w.grad.clone()\n",
    "b3g = model.layers[5].b.grad.clone()\n",
    "w4g = model.layers[7].w.grad.clone()\n",
    "b4g = model.layers[7].b.grad.clone()\n",
    "\n",
    "x_train2 = x_train.clone().requires_grad_(True)\n",
    "model.layers[1].w.data.requires_grad_(True)\n",
    "model.layers[1].b.data.requires_grad_(True)\n",
    "model.layers[3].w.data.requires_grad_(True)\n",
    "model.layers[3].b.data.requires_grad_(True)\n",
    "model.layers[5].w.data.requires_grad_(True)\n",
    "model.layers[5].b.data.requires_grad_(True)\n",
    "model.layers[7].w.data.requires_grad_(True)\n",
    "model.layers[7].b.data.requires_grad_(True)\n",
    "\n",
    "loss = loss_fn(model(x_train2), y_train)\n",
    "loss.backward()\n",
    "\n",
    "test_near(w1g, model.layers[1].w.data.grad)\n",
    "test_near(b1g, model.layers[1].b.data.grad)\n",
    "test_near(w2g, model.layers[3].w.data.grad)\n",
    "test_near(b2g, model.layers[3].b.data.grad)\n",
    "test_near(w3g, model.layers[5].w.data.grad)\n",
    "test_near(b3g, model.layers[5].b.data.grad)\n",
    "test_near(w4g, model.layers[7].w.data.grad)\n",
    "test_near(b4g, model.layers[7].b.data.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_mnist_data()\n",
    "x_train, y_train, x_valid, y_valid = x_train[:8], y_train[:8], x_valid[:2], y_valid[:2]\n",
    "\n",
    "data_bunch = get_data_bunch(x_train, y_train, x_valid, y_valid, batch_size=64)\n",
    "model = get_conv_pool_model(data_bunch)\n",
    "loss_fn = CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential)\n",
       "\t(Layer1) Reshape(1, 28, 28)\n",
       "\t(Layer2) Conv2D(in: 1, out: 4, kernel: 5, stride: 2, pad: 1)\n",
       "\t(Layer3) AvgPool2d(kernel: 2, stride: 1, pad: 0)\n",
       "\t(Layer4) Conv2D(in: 4, out: 16, kernel: 3, stride: 2, pad: 0)\n",
       "\t(Layer5) Flatten()\n",
       "\t(Layer6) Linear(400, 64)\n",
       "\t(Layer7) ReLU()\n",
       "\t(Layer8) Linear(64, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(x_train), y_train)\n",
    "loss_fn.backward()\n",
    "model.backward()\n",
    "\n",
    "xtg = x_train.g.clone()\n",
    "w1g = model.layers[1].w.grad.clone()\n",
    "b1g = model.layers[1].b.grad.clone()\n",
    "w2g = model.layers[3].w.grad.clone()\n",
    "b2g = model.layers[3].b.grad.clone()\n",
    "w3g = model.layers[5].w.grad.clone()\n",
    "b3g = model.layers[5].b.grad.clone()\n",
    "w4g = model.layers[7].w.grad.clone()\n",
    "b4g = model.layers[7].b.grad.clone()\n",
    "\n",
    "x_train2 = x_train.clone().requires_grad_(True)\n",
    "model.layers[1].w.data.requires_grad_(True)\n",
    "model.layers[1].b.data.requires_grad_(True)\n",
    "model.layers[3].w.data.requires_grad_(True)\n",
    "model.layers[3].b.data.requires_grad_(True)\n",
    "model.layers[5].w.data.requires_grad_(True)\n",
    "model.layers[5].b.data.requires_grad_(True)\n",
    "model.layers[7].w.data.requires_grad_(True)\n",
    "model.layers[7].b.data.requires_grad_(True)\n",
    "\n",
    "loss = loss_fn(model(x_train2), y_train)\n",
    "loss.backward()\n",
    "\n",
    "test_near(w1g, model.layers[1].w.data.grad)\n",
    "test_near(b1g, model.layers[1].b.data.grad)\n",
    "test_near(w2g, model.layers[3].w.data.grad)\n",
    "test_near(b2g, model.layers[3].b.data.grad)\n",
    "test_near(w3g, model.layers[5].w.data.grad)\n",
    "test_near(b3g, model.layers[5].b.data.grad)\n",
    "test_near(w4g, model.layers[7].w.data.grad)\n",
    "test_near(b4g, model.layers[7].b.data.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
