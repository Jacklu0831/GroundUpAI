<!DOCTYPE html>
<html lang="en"> 
<head>
    <title>GroundUpAI Documentation</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">    
    <link rel="shortcut icon" href="assets/icons/favicon.ico">  
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <script defer src="assets/fontawesome/js/all.js"></script>
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
    <link rel="stylesheet" href="assets/plugins/prism/prism.css">
    <link rel="stylesheet" href="assets/plugins/lightbox/dist/ekko-lightbox.css">
    <link rel="stylesheet" href="assets/plugins/elegant_font/css/style.css">
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">
</head> 

<body class="body-gray">
    <div class="page-wrapper">
        <!-- Header -->
        <header id="header" class="header">
            <div class="container">
                <div class="branding">
                    <h1 class="logo">
                        <span aria-hidden="true" class="icon_documents_alt icon"></span>
                        <span class="text-bold">GroundUp</span><span class="text-bold-highlight">AI</span>
                    </h1>
                </div>
                <ol class="breadcrumb">
                    <li class="breadcrumb-item"><a href="index.html">Home</a></li>
                    <li class="breadcrumb-item active">Demo</li>
                </ol>
            </div><!--//container-->
        </header><!--//header-->
        
        <div class="doc-wrapper">
            <div class="container">
                <div id="doc-header" class="doc-header text-center">
                    <h1 class="doc-title"><span aria-hidden="true" class="icon icon_datareport_alt"></span> Demo</h1>
                    <div class="meta"><i class="far fa-clock"></i>&nbsp; Last updated: May 2<sup>nd</sup>, 2020</div>
                </div><!--//doc-header-->
                <div class="doc-body row">
                    <div class="doc-content col-md-9 col-12 order-1">
                        <div class="content-inner">
                            <section>
                                <div class="callout-block callout-info">
                                    <div class="icon-holder">
                                        <i class="fas fa-bullhorn"></i>
                                    </div><!--//icon-holder-->
                                    <div class="content">
                                        <h4 class="callout-title">Quick Note</h4>
                                        <p>Though they are not strictly connected, I recommend viewing the 4 sections in order to know how to not only train a model, but to make your own custom training procedure.</p>
                                    </div><!--//content-->
                                </div><!--//callout-->
                            </section>
                            <section id="building-your-model" class="doc-section">
                                <h2 class="section-title">Building Your Model</h2>
                                <p class="source"><a href="https://github.com/Jacklu0831/GroundUpAI/blob/master/demo/00_building_your_model.ipynb" target="_blank"><i class="fas fa-external-link-square-alt"></i> source</a></p>
                                <div class="section-block">
                                    <h3 class="block-title">1. Import</h3>
                                    <p>Importing <i>batch_norm</i> would also recursively import all of it's dependencies. Reducing the need of having many import statements.</p>
                                    <pre><code class="language-python">from batch_norm import *</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">2. Layers</h3>
                                    <p>Building a model is incredibly simple. The comments in the snippet are the output dimensions of each layer for clarity. Now that we have a model, it will be used in the two final sections of this demo.</p>
                                    <pre><code class="language-python">model = Sequential(Reshape((1, 28, 28)),
                   Conv(c_in=1, c_out=4, k_s=5, stride=2, pad=1), # 4, 13, 13
                   AvgPool(k_s=2, pad=0), # 4, 12, 12
                   BatchNorm(4),
                   Conv(c_in=4, c_out=16, stride=2, leak=1.), # 16, 5, 5
                   BatchNorm(16),
                   Flatten(),
                   Linear(400, 64), # 16 * 5 * 5 -> 400
                   ReLU(),
                   Linear(64, 10, True))</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">3. Display Model</h3>
                                    <p>Custom <i>__repr__</i> methods let classes to be neatly displayed. It also works for nested models as shown in this <a href="https://github.com/Jacklu0831/GroundUpAI/blob/master/notebooks/13_sub_model.ipynb">notebook.</a></p>
                                    <pre><code class="language-python">model</code></pre>
                                    <pre><output class="language-none">(Model)
    Reshape(1, 28, 28)
    Conv(1, 4, 5, 2)
    AvgPool(2, 1)
    BatchNorm()
    Conv(4, 16, 3, 2)
    BatchNorm()
    Flatten()
    Linear(400, 64)
    ReLU()
    Linear(64, 10)</output></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">4. Display Parameters</h3>
                                    <p>Printing out parameters' information is also useful for debugging. Here is how to print out all model parameters.</p>
                                    <pre><code class="language-python">for p in model.parameters():
    print(p)</code></pre>
                                    <pre><output class="language-none">shape: (4, 1, 5, 5), grad: True
shape: (4,), grad: True
shape: (1, 4, 1, 1), grad: True
shape: (1, 4, 1, 1), grad: True
shape: (16, 4, 3, 3), grad: True
shape: (16,), grad: True
shape: (1, 16, 1, 1), grad: True
shape: (1, 16, 1, 1), grad: True
shape: (400, 64), grad: True
shape: (64,), grad: True
shape: (64, 10), grad: True
shape: (10,), grad: True</output></pre>
                                    <p>If you want to only look into a selected layer, here it is how.</p>
                                    <pre><code class="language-python">print(f'layer2: {model.layers[1]}\n')
for p in model.layers[1].parameters():
    print(p)</code></pre>
                                    <pre><output class="language-none">layer2:     Conv(1, 4, 5, 2)

shape: (4, 1, 5, 5), grad: True
shape: (4,), grad: True</output></pre>
                                </div><!--//section-block-->
                            </section><!--//doc-section-->
                            

                            <section id="making-a-callback" class="doc-section">
                                <h2 class="section-title">Making a Callback</h2>
                                <p class="source"><a href="https://github.com/Jacklu0831/GroundUpAI/blob/master/demo/01_making_a_callback.ipynb" target="_blank"><i class="fas fa-external-link-square-alt"></i> source</a></p>
                                <div class="section-block">
                                    <h3 class="block-title">1. Import</h3>
                                    <pre><code class="language-python">from callback import *</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">2. Making the Callback</h3>
                                    <p>I decided to use <i>LearningRateSearch</i> as our example since it will be used in the next section of this demo. As shown, before each batch, the callback would try a new learning rate while keeping track of the best learning rate (measured by loss) so far and automatically stop training after loss increases 10x or we have tried enough learning rates.</p>
                                    <pre><code class="language-python">class LearningRateSearch(Callback):
    def __init__(self, max_iter=1000, min_lr=1e-4, max_lr=1):
        self.max_iter = max_iter # max number of candidates learning rates to try
        self.min_lr = min_lr  # lowest/starting candidate learning rate
        self.max_lr = max_lr  # highest candidate learning rate
        self.cur_lr = min_lr  # current candidate learning rate holder 
        self.best_lr = min_lr # recorded learning rate with the lowest loss
        self.best_loss = float('inf') # lowest loss so far
        
    def before_batch(self): 
        # assert training state
        if not self.model.training: return
        # calculate new candidate learning rate
        position = self.iters_count / self.iters
        self.cur_lr = self.min_lr * (self.max_lr/self.min_lr)**position
        # set learning rate in optimizer
        self.optimizer.hyper_params['learning_rate'] = self.cur_lr
        
    def after_step(self):
        # stop when either tried enough times or loss starts increasing
        if self.iters_count >= self.max_iter or self.loss > self.best_loss*10:
            raise CancelTrainException()
        # update best loss and best learning rate
        if self.loss < self.best_loss:
            self.best_loss = self.loss
            self.best_lr = self.cur_lr</code></pre>
                                </div><!--//section-block-->
                            </section><!--//doc-section-->
                            

                            <section id="lr-search" class="doc-section">
                                <h2 class="section-title">Learning Rate Search</h2>
                                <p class="source"><a href="https://github.com/Jacklu0831/GroundUpAI/blob/master/demo/02_lr_search_n_training.ipynb" target="_blank"><i class="fas fa-external-link-square-alt"></i> source</a></p>
                                <div class="section-block">
                                    <h3 class="block-title">1. Import</h3>
                                    <pre><code class="language-python">from stateful_optim import *</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">2. Data Bunch, Loss Function</h3>
                                    <p>Let's retrieve the data bunch and loss function each using just one line. Since we are training on <a href="http://yann.lecun.com/exdb/mnist/">MNIST handwritten digits</a>, cross entropy is an appropriate loss function to use.</p>
                                    <pre><code class="language-python">data_bunch = get_data_bunch(*get_mnist_data(), batch_size=64)
loss_fn = CrossEntropy()</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">3. Model, Adam, Callbacks, Learner</h3>
                                    <ul class="list">
                                        <li>model: grab the model from the first section of the demo.</li>
                                        <li>optimizer: use the <i>adam_opt</i> util function to grab an adam optimizer</li>
                                        <li>callbacks: use the <i>LearningRateSearch</i> callback built in the last section and <i>Recorder</i> to record the history values of hyperparameters.</li>
                                    </ul>
                                    <pre><code class="language-python">model = get_conv_final_model(data_bunch)
optimizer = adam_opt(model, learning_rate=1e-3, weight_decay=1e-4)
callbacks = [LearningRateSearch(min_lr=1e-5, max_lr=1e-2), Recorder()]</code></pre>
                                    <p>For model training, the best practice is to throw all components from above into a learner class, which is able to interact with callbacks in various stages of training.</p>
                                    <p> By printing out the learner class, again with custom <i>__repr__</i>, we can view details on the <i>data bunch, model architecture, loss function, optimizer steppers, and callbacks</i>.</p>
                                    <pre><code class="language-python">learner = Learner(data_bunch, model, loss_fn, optimizer, callbacks)
print(learner)</code></pre>
                                    <pre><output class="language-python">(DataBunch) 
    (DataLoader) 
        (Dataset) x: (50000, 784), y: (50000,)
        (Sampler) total: 50000, batch_size: 64, shuffle: True
    (DataLoader) 
        (Dataset) x: (10000, 784), y: (10000,)
        (Sampler) total: 10000, batch_size: 128, shuffle: False
(Model)
    Reshape(1, 28, 28)
    Conv(1, 4, 5, 2)
    AvgPool(2, 1)
    BatchNorm()
    Conv(4, 16, 3, 2)
    BatchNorm()
    Flatten()
    Linear(400, 64)
    ReLU()
    Linear(64, 10)
(CrossEntropy)
(StatefulOpt) steppers: ['adam', 'l2_reg'], stats: ['ExpWeightedGrad', 'ExpWeightedSqrGrad', 'StepCount']
(Callbacks) ['TrainEval', 'LearningRateSearch', 'Recorder']</output></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">4. One Epoch Fit</h3>
                                    <p>To find our learning rate, simply do a 1 epoch fit. Recall from <i>Making a Callback</i> that the LearningRateSearch callback performs <i>early stopping</i> once it is confident in having the learning rate that yields the lowest loss.</p>
                                    <pre><code class="language-python">learner.fit(1)</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">5. Display Loss vs. Learning Rate</h3>
                                    <p>By passing the <i>Recorder</i> callback into the util function <i>plot_lr_loss</i>, we can see the relationship between loss vs. learning rate.</p>
                                    <pre><code class="language-python">plot_lr_loss(learner.callbacks[2])</code></pre>
                                    <img class="img-fluid imgout" src="assets/images/demo/loss_vs_lr.png" alt="screenshot" />
                                    <br><br>
                                    <p>Lastly, the <i>LearningRateSearch</i> callback also kept track of the best learning rate candidate for our use in the final section.</p>
                                    <pre><code class="language-python">lr = learner.callbacks[1].best_lr
print(f'learning rate found: {lr}')</code></pre>
                                    <pre><output class="language-none">learning rate found: 0.004283273648329838</output></pre>
                                </div><!--//section-block-->
                            </section><!--//doc-section-->

                            <section id="model-training" class="doc-section">
                                <h2 class="section-title">Model Training</h2>
                                <p class="source"><a href="https://github.com/Jacklu0831/GroundUpAI/blob/master/demo/02_lr_search_n_training.ipynb" target="_blank"><i class="fas fa-external-link-square-alt"></i> source</a></p>
                                <div class="section-block">
                                    <h3 class="block-title">1. Import</h3>
                                    <p>Same as previous sections, import modules, then grab data bunch and loss function.
                                    <pre><code class="language-python">from stateful_optim import *</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">2. Data Bunch, Loss Function</h3>
                                    <pre><code class="language-python">data_bunch = get_data_bunch(*get_mnist_data(), batch_size=64)
loss_fn = CrossEntropy()</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">3. Cosine Parameter Scheduling</h3>
                                    <p>New callback alert! Please refer to the <a href="../BuildingBlocks.html">code documentation</a> to familiarize with the <i>ParamScheduler</i> callback. Here we build a custom cosine schedule for the learning rate that takes place each epoch using the learning rate from the last section.</p>
                                    <pre><code class="language-python">schedule = combine_schedules([0.4, 0.6], one_cycle_cos(lr/3, lr*3, lr/3))</code></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">4. Model, Adam, Callbacks, Learner</h3>
                                    <p>Same as before, create model, optimizer, and callbacks. Notice that <i>LearningRateSearch</i> is no longer needed and that the <i>ParamScheduler</i> is now used for training with dynamic learning rate per epoch. I also added <i>StatsLogging</i> to print out loss and accuracy per epoch.</p>
                                    <pre><code class="language-python">model = get_conv_final_model(data_bunch)
optimizer = adam_opt(model, learning_rate=lr, weight_decay=1e-4)
callbacks = [ParamScheduler('learning_rate', schedule), StatsLogging(), Recorder()]</code></pre>
                                    <pre><code class="language-python">learner = Learner(data_bunch, model, loss_fn, optimizer, callbacks)
print(learner)</code></pre>
                                    <pre><output class="language-none">(DataBunch) 
    (DataLoader) 
        (Dataset) x: (50000, 784), y: (50000,)
        (Sampler) total: 50000, batch_size: 64, shuffle: True
    (DataLoader) 
        (Dataset) x: (10000, 784), y: (10000,)
        (Sampler) total: 10000, batch_size: 128, shuffle: False
(Model)
    Reshape(1, 28, 28)
    Conv(1, 4, 5, 2)
    AvgPool(2, 1)
    BatchNorm()
    Conv(4, 16, 3, 2)
    BatchNorm()
    Flatten()
    Linear(400, 64)
    ReLU()
    Linear(64, 10)
(CrossEntropy)
(StatefulOpt) steppers: ['adam', 'l2_reg'], stats: ['ExpWeightedGrad', 'ExpWeightedSqrGrad', 'StepCount']
(Callbacks) ['TrainEval', 'ParamScheduler', 'StatsLogging', 'Recorder']</output></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">5. Train Model</h3>
                                    <p>Training is as simple as just calling the <i>fit</i> method with number of epochs. As shown below, the validation accuracy rises to 97.3 in just 3 epochs.</p>
                                    <pre><code class="language-python">learner.fit(3)</code></pre>
                                    <pre><output class="language-python">Epoch - 1
train metrics - [5.624208450317383e-06, 0.89082]
valid metrics - [2.2692584991455077e-05, 0.9622]

Epoch - 2
train metrics - [6.513986587524414e-06, 0.95746]
valid metrics - [2.0359230041503905e-05, 0.9706]

Epoch - 3
train metrics - [6.942987442016601e-06, 0.96688]
valid metrics - [1.5890932083129882e-05, 0.9731]</output></pre>
                                </div><!--//section-block-->
                                <div class="section-block">
                                    <h3 class="block-title">6. Loss and Learning Rate</h3>
                                    <p>Lastly, plot the loss and learning rate recorded by the <i>Recorder</i> callback.</p>
                                    <pre><code class="language-python">learner.callbacks[3].plot_losses()</code></pre>
                                    <img class="img-fluid imgout" src="assets/images/demo/loss.png" alt="screenshot" />
                                    <br><br>
                                    <p>As shown below, the learning rate values make a cosine-ish cycle each epoch, showing that our <i>ParamScheduler</i> callback is working properly.</p>
                                    <pre><code class="language-python">learner.callbacks[3].plot_parameter('learning_rate')</code></pre>
                                    <img class="img-fluid imgout" src="assets/images/demo/lr.png" alt="screenshot" />
                                </div><!--//section-block-->
                            </section><!--//doc-section-->

                        </div><!--//content-inner-->
                    </div><!--//doc-content-->
                    <div class="doc-sidebar col-md-3 col-12 order-0 d-none d-md-flex">
                        <div id="doc-nav" class="doc-nav">
                            <nav id="doc-menu" class="nav doc-menu flex-column sticky">
                                <a class="nav-link scrollto" href="#building-your-model">Building Your Model</a>
                                <a class="nav-link scrollto" href="#making-a-callback">Making a Callback</a>
                                <a class="nav-link scrollto" href="#lr-search">Learning Rate Search</a>
                                <a class="nav-link scrollto" href="#model-training">Model Training</a>
                            </nav><!--//doc-menu-->
                        </div>
                    </div><!--//doc-sidebar-->
                </div><!--//doc-body-->              
            </div><!--//container-->
        </div><!--//doc-wrapper-->
    </div><!--//page-wrapper-->
    
    
    <footer id="footer" class="footer text-center">
        <div class="container">
            <small class="copyright">&copy; Documentation template designed by <a href="https://themes.3rdwavemedia.com/" target="_blank">Xiaoying Riley</a></small>
        </div><!--//container-->
    </footer><!--//footer-->
    
    <!-- Main Javascript -->          
    <script type="text/javascript" src="assets/plugins/jquery-3.4.1.min.js"></script>
    <script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="assets/plugins/prism/prism.js"></script>    
    <script type="text/javascript" src="assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script>  
    <script type="text/javascript" src="assets/plugins/lightbox/dist/ekko-lightbox.min.js"></script>   
    <script type="text/javascript" src="assets/plugins/stickyfill/dist/stickyfill.min.js"></script>
    <script type="text/javascript" src="assets/js/main.js"></script>
    
</body>
</html> 