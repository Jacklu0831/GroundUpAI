                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;DEF</span></td>
                                            <td><span class="name">TConvNReLU</span></td>
                                            <td class="expand"><span class="params">(i, o, norm, k=3, s=2, b=True)</span></td>
                                        </table>
                                        <p><span class="desc">Tranpose convolutional layer + normalization layer + ReLU activation.</span></p>
                                        <ul class="list">
                                           <li><b>i</b>: channel in</li>
                                           <li><b>o</b>: channel out</li>
                                           <li><b>norm</b>: normalization layer</li>
                                           <li><b>k</b>: kernel size</li>
                                           <li><b>s</b>: stride size</li>
                                           <li><b>b</b>: whether to have bias or not in TransposeConv</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;DEF</span></td>
                                            <td><span class="name">PadConvNReLU</span></td>
                                            <td class="expand"><span class="params">(i, o, norm, pad_mode, k=3, s=1, p=1, b=True, act=True, init=nn.init.kaiming_normal_)</span></td>
                                        </table>
                                        <p><span class="desc">PaddedConvolutional layer + normalization layer + ReLU activation.</span></p>
                                        <ul class="list">
                                           <li><b>i</b>: channel in</li>
                                           <li><b>o</b>: channel out</li>
                                           <li><b>norm</b>: normalization layer</li>
                                           <li><b>pad_mode</b>: padding mode ('reflection', 'border', or 'zeros')</li>
                                           <li><b>k</b>: kernel size</li>
                                           <li><b>s</b>: stride size</li>
                                           <li><b>p</b>: padding size</li>
                                           <li><b>b</b>: bias or not in TransposeConv</li>
                                           <li><b>act</b>: whether to append ReLU after PadConvN</li>
                                           <li><b>init</b>: initialization function</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;CLS</span></td>
                                            <td><span class="name">ResnetBlock(nn.Module)</span></td>
                                            <td class="expand"><span class="params">(d, pad_mode, norm=None, dropout=0., b=True)</span></td>
                                        </table>
                                        <p><span class="desc">ResBlock ( y = F(x) + x).</span></p>
                                        <ul class="list">
                                           <li><b>d</b>: channel in</li>
                                           <li><b>pad_mode</b>: padding mode (either "reflection" or "zero")</li>
                                           <li><b>norm</b>: normalization layer</li>
                                           <li><b>dropout</b>: dropout factor (0 to 1)</li>
                                           <li><b>b</b>: whether to have bias or not in TransposeConv</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;DEF</span></td>
                                            <td><span class="name">generator</span></td>
                                            <td class="expand"><span class="params">(i, o, c=64, norm=None, dropout=0., depth=6, pad_mode='reflection')</span></td>
                                        </table>
                                        <p><span class="desc">Generator of GAN (resnet based).</span></p>
                                        <ul class="list">
                                           <li><b>i</b>: channel in</li>
                                           <li><b>o</b>: channel out</li>
                                           <li><b>c</b>: start channel (changes are resnet is being built)</li>
                                           <li><b>norm</b>: normalization layer</li>
                                           <li><b>dropout</b>: dropout factor (0 to 1)</li>
                                           <li><b>depth</b>: resnet depth</li>
                                           <li><b>pad_mode</b>: padding mode (either "reflection" or "zero")</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;DEF</span></td>
                                            <td><span class="name">ConvNLReLU</span></td>
                                            <td class="expand"><span class="params">(i, o, norm, k=3, s=1, p=1, b=True, act=True, slope=0.2, init=nn.init.kaiming_normal_)</span></td>
                                        </table>
                                        <p><span class="desc">Convolutional layer + normalization layer + ReLU activation.</span></p>
                                        <ul class="list">
                                           <li><b>i</b>: channel in</li>
                                           <li><b>o</b>: channel out</li>
                                           <li><b>norm</b>: normalization layer</li>
                                           <li><b>k</b>: kernel size</li>
                                           <li><b>s</b>: stride size</li>
                                           <li><b>p</b>: padding size</li>
                                           <li><b>b</b>: bias or not in TransposeConv</li>
                                           <li><b>act</b>: whether to append ReLU after PadConvN</li>
                                           <li><b>slope</b>: leaky relu slope</li>
                                           <li><b>init</b>: initialization function</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;DEF</span></td>
                                            <td><span class="name">discriminator</span></td>
                                            <td class="expand"><span class="params">(i, c=64, norm=None, n_layer=3, act=False)</span></td>
                                        </table>
                                        <p><span class="desc">Discriminator of GAN.</span></p>
                                        <ul class="list">
                                           <li><b>i</b>: channel in</li>
                                           <li><b>c</b>: start channel (changes as we build the discriminator blocks)</li>
                                           <li><b>norm</b>: normalization layer</li>
                                           <li><b>n_layer</b>: number of discriminator blocks</li>
                                           <li><b>act</b>: whether to append activation at the end of discriminator</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;CLS</span></td>
                                            <td><span class="name">CycleGAN(nn.Module)</span></td>
                                            <td class="expand"><span class="params">(i, o, c=64, norm=None, gen_layers=6, dis_layers=3, dropout=0., lsgan=True)</span></td>
                                        </table>
                                        <p><span class="desc">Cycle GAN with two generators and discriminators.</span></p>
                                        <ul class="list">
                                           <li><b>i</b>: channel in</li>
                                           <li><b>o</b>: channel out</li>
                                           <li><b>c</b>: start channel (dynamic)</li>
                                           <li><b>norm</b>: normalization layer</li>
                                           <li><b>gen_layers</b>: number of generator blocks</li>
                                           <li><b>dis_layer</b>: number of discriminator blocks</li>
                                           <li><b>dropout</b>: dropout factor (0 to 1)</li>
                                           <li><b>lsgan</b>: boolean factor for least square gan (https://arxiv.org/abs/1611.04076)</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;CLS</span></td>
                                            <td><span class="name">AdaptiveLoss(nn.Module)</span></td>
                                            <td class="expand"><span class="params">(critic)</span></td>
                                        </table>
                                        <p><span class="desc">Critic wrapper for creating binary target tensors for loss computation.</span></p>
                                        <ul class="list">
                                           <li><b>critic</b>: loss module</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;CLS</span></td>
                                            <td><span class="name">CycleGANLoss(nn.Module)</span></td>
                                            <td class="expand"><span class="params">(cycleGAN, w1=10., w2=10., wi=0.5, lsgan=True)</span></td>
                                        </table>
                                        <p><span class="desc">Cycle GAN loss layer with identity loss, generator loss, and discriminator loss.</span></p>
                                        <ul class="list">
                                           <li><b>cycleGAN</b>: cycle gan model</li>
                                           <li><b>w1</b>: lambda factor for loss in domain 1</li>
                                           <li><b>w2</b>: lambda factor for loss in domain 2</li>
                                           <li><b>wi</b>: lambda factor for identity loss</li>
                                           <li><b>lsgan</b>: factor for https://arxiv.org/abs/1611.04076</li>
                                        </ul>
                                    </div>
                                </div>

                                <div class="section-block-small">
                                    <div class="doc-block">
                                        <table>
                                           <td><span class="label">&nbsp;CLS</span></td>
                                            <td><span class="name">CycleGANTrainer(LearnerCallback)</span></td>
                                            <td class="expand"><span class="params">()</span></td>
                                        </table>
                                        <p><span class="desc">Callback for the special training procedure of Cycle GAN.</span></p>
                                    </div>
                                </div>